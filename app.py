import streamlit as st
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv
from datetime import datetime
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# YÃ¼klemeler
load_dotenv()
API_KEY = os.getenv("API_KEY")
genai.configure(api_key=API_KEY)

model = genai.GenerativeModel("gemini-2.0-flash")

st.set_page_config(page_title="BrainDrop", page_icon="ğŸ§ ")

st.title("ğŸ§  BrainDrop")
st.markdown("Her gÃ¼n Ã¶ÄŸrendiÄŸin bir bilgiyi bÄ±rak, biz senin iÃ§in Ã¶zetleyelim, etiketleyelim ve motive edelim!")

user_input = st.text_area("BugÃ¼n ne Ã¶ÄŸrendin?")

learning_goal = st.text_input("BugÃ¼n iÃ§in Ã¶ÄŸrenme hedefiniz nedir? (Opsiyonel)")
future_plan = st.text_area("Ã–ÄŸrendiklerini nasÄ±l uygulayacaÄŸÄ±nÄ±zÄ± planlÄ±yorsunuz? (Opsiyonel)")

if st.button("GÃ¶nder") and user_input.strip() != "":
    with st.spinner("Yapay zeka dÃ¼ÅŸÃ¼nÃ¼rken biraz bekleyelim..."):
        prompt = f"""
        KullanÄ±cÄ± bugÃ¼n ÅŸÃ¶yle yazdÄ±:
        "{user_input}"

        AÅŸaÄŸÄ±dakileri yap:
        1. Bu girdiyi Ã¶zetle (1 cÃ¼mle).
        2. Konu etiketi Ã¼ret (sadece 1-2 kelime).
        3. Motive edici kÄ±sa bir geri bildirim ver.
        Sonucu ÅŸu formatta ver:
        Ã–zet: ...
        Etiket: ...
        Yorum: ...
        """
        response = model.generate_content(prompt)

    lines = response.text.strip().split("\n")
    summary = next((l for l in lines if l.startswith("Ã–zet:")), "Ã–zet: BulunamadÄ±")
    topic = next((l for l in lines if l.startswith("Etiket:")), "Etiket: BulunamadÄ±")
    comment = next((l for l in lines if l.startswith("Yorum:")), "Yorum: BulunamadÄ±")

    st.subheader("ğŸ¯ Ã–zet")
    st.success(summary.replace("Ã–zet:", "").strip())

    st.subheader("ğŸ·ï¸ Etiket")
    st.info(topic.replace("Etiket:", "").strip())

    st.subheader("ğŸ’¬ Yorum")
    st.warning(comment.replace("Yorum:", "").strip())

    log = {
        "tarih": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "girdi": user_input,
        "ozet": summary.replace("Ã–zet:", "").strip(),
        "etiket": topic.replace("Etiket:", "").strip(),
        "yorum": comment.replace("Yorum:", "").strip(),
        "ogrenme_hedefi": learning_goal.strip() if learning_goal else None,
        "gelecek_planÄ±": future_plan.strip() if future_plan else None
    }

    with open("gunlukler.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(log, ensure_ascii=False) + "\n")

# -------------------------------------
# ğŸ“š GEÃ‡MÄ°Å GÃœNLÃœKLERÄ° GÃ–STER
# -------------------------------------

st.markdown("---")
st.subheader("ğŸ“š GeÃ§miÅŸ KayÄ±tlar")

daily_logs = []
if os.path.exists("gunlukler.jsonl"):
    with open("gunlukler.jsonl", "r", encoding="utf-8") as f:
        for line in f:
            try:
                daily_logs.append(json.loads(line))
            except:
                pass

etiketler = sorted(set(log.get("etiket", "Genel") for log in daily_logs if "etiket" in log))
selected_etiket = st.selectbox("Etikete gÃ¶re filtrele:", ["TÃ¼mÃ¼"] + etiketler)

filtered_logs = daily_logs
if selected_etiket != "TÃ¼mÃ¼":
    filtered_logs = [log for log in filtered_logs if selected_etiket in log.get("etiket", "")]

arama = st.text_input("Anahtar kelime ara:")
if arama:
    filtered_logs = [log for log in filtered_logs if arama.lower() in log.get("girdi", "").lower()]

for log in reversed(filtered_logs):
    tarih_str = log.get("tarih", "")
    st.markdown(f"""
    <div style='border-left: 3px solid #ccc; padding-left: 15px; margin-bottom: 20px;'>
        <strong>ğŸ—“ï¸ {tarih_str}</strong><br>
        <em>ğŸ·ï¸ {log.get("etiket", "")}</em><br>
        <strong>ğŸ§  Ã–zet:</strong> {log.get("ozet", "")}<br>
        <strong>âœï¸ Girdi:</strong> {log.get("girdi", "")}<br>
        <small>ğŸ’¬ {log.get("yorum", "")}</small><br>
        <strong>ğŸ¯ Hedef:</strong> {log.get("ogrenme_hedefi", "BelirtilmemiÅŸ")}<br>
        <strong>ğŸ“ˆ Plan:</strong> {log.get("gelecek_planÄ±", "BelirtilmemiÅŸ")}
    </div>
    """, unsafe_allow_html=True)

# -------------------------------------
# ğŸ“Š Ä°STATÄ°STÄ°KSEL GÃ–RSELLEÅTÄ°RME
# -------------------------------------

st.markdown("---")
st.subheader("ğŸ“ˆ En SÄ±k Ã–ÄŸrenilen Konular")

etiket_sayilari = Counter(log.get("etiket", "Bilinmiyor") for log in daily_logs)
if etiket_sayilari:
    en_sik = etiket_sayilari.most_common(5)
    etiketler, sayilar = zip(*en_sik)

    fig, ax = plt.subplots()
    ax.barh(etiketler, sayilar, color="skyblue")
    ax.invert_yaxis()
    ax.set_xlabel("GÃ¼n SayÄ±sÄ±")
    ax.set_title("En SÄ±k Ã–ÄŸrenilen Konular")
    st.pyplot(fig)
else:
    st.info("HenÃ¼z istatistik gÃ¶sterilecek kadar kayÄ±t yok.")

# -------------------------------------
# â˜ï¸ KELÄ°ME BULUTU
# -------------------------------------

st.markdown("---")
st.subheader("â˜ï¸ Ã–ÄŸrenilen Bilgilerden Kelime Bulutu")

tum_girdiler = " ".join(log.get("girdi", "") for log in daily_logs)
if tum_girdiler.strip():
    wordcloud = WordCloud(width=800, height=400, background_color="white").generate(tum_girdiler)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    st.pyplot(fig)
else:
    st.info("Kelime bulutu oluÅŸturmak iÃ§in yeterli veri yok.")
